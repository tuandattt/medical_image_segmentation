{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGWTPWBIx370"
      },
      "source": [
        "## **1. Installation**\n",
        "\n",
        "Update to Tensorflow 2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dae0rTxJ-bi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm1eXSwx-MOI"
      },
      "outputs": [],
      "source": [
        "# Update CUDA for TF 2.5\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
        "!dpkg -i libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
        "# Check if package has been installed\n",
        "!ls -l /usr/lib/x86_64-linux-gnu/libcudnn.so.*\n",
        "# Upgrade Tensorflow\n",
        "!pip install --upgrade tensorflow==2.5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulXTP0uuBdOl"
      },
      "source": [
        "Install Mask R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md87Hxgtn6zi"
      },
      "outputs": [],
      "source": [
        "!wget https://pysource.com/extra_files/maskrcnn_colab_demo_commit_17.zip\n",
        "!unzip maskrcnn_colab_demo_commit_17.zip\n",
        "import sys\n",
        "sys.path.append(\"/content/maskrcnn_colab/mrcnn_demo\")\n",
        "from m_rcnn import *\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvM9sdw3Vou_"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omb3Yl6ABqiJ"
      },
      "source": [
        "## **2. Image Dataset**\n",
        "\n",
        "Load your annotated dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjrPNJvTcQz1"
      },
      "outputs": [],
      "source": [
        "extract_images(os.path.join(\"/content/\", \"/content/drive/MyDrive/DATA/images_val.zip\"), \"/content/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlNYqGhvqb_p"
      },
      "outputs": [],
      "source": [
        "# Extract Images\n",
        "images_path = \"/content/drive/MyDrive/DATA/images.zip\"\n",
        "annotations_path = \"/content/drive/MyDrive/DATA/Bản sao của labels_thainhi.json\"\n",
        "\n",
        "extract_images(os.path.join(\"/content/\",images_path), \"/content/dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnW8ETPKzqFT"
      },
      "outputs": [],
      "source": [
        "dataset_train = load_image_dataset(os.path.join(\"/content/\", annotations_path), \"/content/dataset\", \"train\")\n",
        "dataset_val = load_image_dataset(os.path.join(\"/content/\", annotations_path), \"/content/dataset\", \"val\")\n",
        "class_number = dataset_train.count_classes()\n",
        "print('Train: %d' % len(dataset_train.image_ids))\n",
        "print('Validation: %d' % len(dataset_val.image_ids))\n",
        "print(\"Classes: {}\".format(class_number))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umeaqvVeBqiL"
      },
      "outputs": [],
      "source": [
        "# Load image samples\n",
        "display_image_samples(dataset_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9k3Wm0_BqiN"
      },
      "source": [
        "##**3. Training**\n",
        "\n",
        "Train Mask RCNN on your custom Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axkqWaZ7z_4p"
      },
      "outputs": [],
      "source": [
        "# Load Configuration\n",
        "config = CustomConfig(class_number)\n",
        "# config.display()\n",
        "model = load_training_model(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyzLXzF5BqiN",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Start Training\n",
        "# This operation might take a long time.\n",
        "train_head(model, dataset_train, dataset_val, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiSFtnMXWifw"
      },
      "source": [
        "##**3.2 Training 2:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw1bbyP9P8bi"
      },
      "outputs": [],
      "source": [
        "def load_continue_training_model(config):\n",
        "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                              model_dir=MODEL_DIR)\n",
        "\n",
        "    # Which weights to start with?\n",
        "    init_with = \"last\"  # imagenet, coco, or last\n",
        "\n",
        "    if init_with == \"imagenet\":\n",
        "        model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "    elif init_with == \"coco\":\n",
        "        # Load weights trained on MS COCO, but skip layers that\n",
        "        # are different due to the different number of classes\n",
        "        # See README for instructions to download the COCO weights\n",
        "        print(COCO_MODEL_PATH)\n",
        "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "    elif init_with == \"last\":\n",
        "        # Load the last model you trained and continue training\n",
        "        model.load_weights(model.find_last(), by_name=True)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB7Pv_vzOMbk"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/maskrcnn_colab/logs/object20221130T0229/mask_rcnn_object_0004.h5'\n",
        "model_1, inference_config = load_inference_model(class_number, model_path)\n",
        "model_1 = load_training_model(inference_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ur78Uy4JIch"
      },
      "outputs": [],
      "source": [
        "class CustomDataset_1(utils.Dataset):\n",
        "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n",
        "        See http://cocodataset.org/#home for more information.\n",
        "    \"\"\"\n",
        "\n",
        "    def load_custom_1(self, annotation_json, images_dir, dataset_type=\"train\"):\n",
        "        \"\"\" Load the coco-like dataset from json\n",
        "        Args:\n",
        "            annotation_json: The path to the coco annotations json file\n",
        "            images_dir: The directory holding the images referred to by the json file\n",
        "        \"\"\"\n",
        "\n",
        "        # Load json from file\n",
        "        print(\"Annotation json path: \", annotation_json)\n",
        "        json_file = open(annotation_json)\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "\n",
        "\n",
        "        # Add the class names using the base method from utils.Dataset\n",
        "        source_name = \"coco_like\"\n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['id']\n",
        "\n",
        "            class_name = category['name']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(\n",
        "                    class_name))\n",
        "                return\n",
        "\n",
        "            self.add_class(source_name, class_id, class_name)\n",
        "\n",
        "        # Get all annotations\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "\n",
        "        # Get all images and add them to the dataset\n",
        "        seen_images = {}\n",
        "\n",
        "        # Split the dataset, if train, get 90%, else 10%\n",
        "        len_images = len(coco_json['images'])\n",
        "        if dataset_type == \"train\":\n",
        "            img_range = [0, len_images]\n",
        "        else:\n",
        "            img_range = [0, 0]\n",
        "\n",
        "        for i in range(img_range[0], img_range[1]):\n",
        "            image = coco_json['images'][i]\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "\n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
        "                image_annotations = annotations[image_id]\n",
        "\n",
        "                # Add the image using the base method from utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Load instance masks for the given image.\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
        "        Args:\n",
        "            image_id: The id of the image to load masks for\n",
        "        Returns:\n",
        "            masks: A bool array of shape [height, width, instance count] with\n",
        "                one mask per instance.\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "\n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "        #print(\"Class_ids, \", class_ids)\n",
        "        return mask, class_ids\n",
        "\n",
        "    def count_classes_1(self):\n",
        "        class_ids = set()\n",
        "        for image_id in self.image_ids:\n",
        "            image_info = self.image_info[image_id]\n",
        "            annotations = image_info['annotations']\n",
        "\n",
        "            for annotation in annotations:\n",
        "                class_id = annotation['category_id']\n",
        "                class_ids.add(class_id)\n",
        "\n",
        "        class_number = len(class_ids)\n",
        "        return class_number\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0cXGfbnJrJD"
      },
      "outputs": [],
      "source": [
        "def load_image_dataset_custom(annotation_path, dataset_path, dataset_type):\n",
        "    dataset_train = CustomDataset_1()\n",
        "    dataset_train.load_custom_1(annotation_path, dataset_path, dataset_type)\n",
        "    dataset_train.prepare()\n",
        "    return dataset_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sstq7v0MWlCw"
      },
      "outputs": [],
      "source": [
        "#Extract Images\n",
        "images_path_val = \"/content/drive/MyDrive/DATA/images_val.zip\"\n",
        "annotations_path_val = \"/content/drive/MyDrive/DATA/labels_thainhi_val.json\"\n",
        "\n",
        "extract_images(os.path.join(\"/content/\",images_path_val), \"/content/dataset_valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkoG0-aYW0GZ"
      },
      "outputs": [],
      "source": [
        "dataset_train_1 = load_image_dataset_custom(os.path.join(\"/content/\", annotations_path_val), \"/content/dataset_valid\", \"train\")\n",
        "dataset_val_1 = load_image_dataset_custom(os.path.join(\"/content/\", annotations_path_val), \"/content/dataset_valid\", \"val\")\n",
        "class_number = dataset_train_1.count_classes_1()\n",
        "print('Train: %d' % len(dataset_train_1.image_ids))\n",
        "print('Validation: %d' % len(dataset_val_1.image_ids))\n",
        "print(\"Classes: {}\".format(class_number))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfu9q50gqif3"
      },
      "outputs": [],
      "source": [
        "train_head(model_1, dataset_train_1, dataset_val, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1cg2vLVrvbm"
      },
      "source": [
        "##**3.3 Training 3:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eRDbsH9QjOq"
      },
      "outputs": [],
      "source": [
        "model_path_2 = '/content/maskrcnn_colab/logs/object20221130T0310/mask_rcnn_object_0004.h5'\n",
        "model_2, inference_config_2 = load_inference_model(class_number, model_path_2)\n",
        "model_2 = load_training_model(inference_config_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGDmo502ryD-"
      },
      "outputs": [],
      "source": [
        "#Extract Images\n",
        "images_path_test = \"/content/drive/MyDrive/DATA/images_test.zip\"\n",
        "annotations_path_test = \"/content/drive/MyDrive/DATA/labels_thainhi_test.json\"\n",
        "\n",
        "extract_images(os.path.join(\"/content/\",images_path_test), \"/content/dataset_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDlBHBzZtK3X"
      },
      "outputs": [],
      "source": [
        "dataset_train_2 = load_image_dataset_custom(os.path.join(\"/content/\", annotations_path_test), \"/content/dataset_test\", \"train\")\n",
        "dataset_val_2 = load_image_dataset_custom(os.path.join(\"/content/\", annotations_path_test), \"/content/dataset_test\", \"val\")\n",
        "class_number = dataset_train_2.count_classes_1()\n",
        "print('Train: %d' % len(dataset_train_2.image_ids))\n",
        "print('Validation: %d' % len(dataset_val_2.image_ids))\n",
        "print(\"Classes: {}\".format(class_number))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcjls1ESt3r2"
      },
      "outputs": [],
      "source": [
        "train_head(model_2, dataset_train_2, dataset_val, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6npLKIL3BqiO"
      },
      "source": [
        "## **4. Detection (test your model on a random image)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUwXQ6h7BqiO"
      },
      "outputs": [],
      "source": [
        "# Load Test Model\n",
        "# The latest trained model will be loaded\n",
        "#test_model, inference_config = load_test_model(class_number)\n",
        "model_final, inference_config = load_inference_model(class_number, model.find_last())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMM5p-dUKQsX"
      },
      "outputs": [],
      "source": [
        "test_random_image(model_final, dataset_val, inference_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA6EL1KNx0mM"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/DATA/images_N.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/DATA/Datasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwCa0aHtyYcN"
      },
      "outputs": [],
      "source": [
        "!pip install py7zr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FooHO8yaybQ8"
      },
      "outputs": [],
      "source": [
        "# x MyImageData.zip.001\n",
        "!7za x /content/drive/MyDrive/DATA/images_N.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtwfLvXlybqS"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "list_path_file = list(glob.glob(\"/content/drive/MyDrive/DATA/Datasets/images/*\"))\n",
        "list_path_file[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ngy_ikQgsx_0"
      },
      "outputs": [],
      "source": [
        "len(list_path_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_instances_custom(image, boxes, masks, class_ids, class_names,\n",
        "                      scores=None, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=True,\n",
        "                      colors=None, captions=None):\n",
        "    \"\"\"\n",
        "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
        "    masks: [height, width, num_instances]\n",
        "    class_ids: [num_instances]\n",
        "    class_names: list of class names of the dataset\n",
        "    scores: (optional) confidence scores for each box\n",
        "    title: (optional) Figure title\n",
        "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
        "    figsize: (optional) the size of the image\n",
        "    colors: (optional) An array or colors to use with each object\n",
        "    captions: (optional) A list of strings to use as captions for each object\n",
        "    \"\"\"\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display * \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # If no axis is passed, create one and automatically call show()\n",
        "    auto_show = False\n",
        "    if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "        auto_show = True\n",
        "\n",
        "    # Generate random colors\n",
        "    colors = colors or random_colors(N, opencv=False)\n",
        "\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    ax.set_ylim(height + 10, -10)\n",
        "    ax.set_xlim(-10, width + 10)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "    for i in range(N):\n",
        "        color = colors[i]\n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "            ax.add_patch(p)\n",
        "\n",
        "        # Label\n",
        "        if not captions:\n",
        "            class_id = class_ids[i]\n",
        "            score = scores[i] if scores is not None else None\n",
        "            label = class_names[class_id]\n",
        "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
        "        else:\n",
        "            caption = captions[i]\n",
        "        ax.text(x1, y1 + 8, caption,\n",
        "                color='w', size=11, backgroundcolor=\"none\")\n",
        "\n",
        "        # Mask\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = apply_mask(masked_image, mask, color)\n",
        "\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "            ax.add_patch(p)\n",
        "    ax.imshow(masked_image.astype(np.uint8))\n",
        "    if auto_show:\n",
        "        plt.show()\n",
        "    return masked_image"
      ],
      "metadata": {
        "id": "KbWM2_Yy3Pvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_colors(N, bright=True, opencv=True):\n",
        "    \"\"\"\n",
        "    Generate random colors.\n",
        "    To get visually distinct colors, generate them in HSV space then\n",
        "    convert to RGB.\n",
        "    \"\"\"\n",
        "    brightness = 255 if bright else 180\n",
        "    if opencv is False:\n",
        "        brightness = 1 if bright else 0.7\n",
        "    hsv = [(i / N + 1, 1, brightness) for i in range(N + 1)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return colors"
      ],
      "metadata": {
        "id": "o0z315RbF3_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import itertools\n",
        "import colorsys\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches,  lines\n",
        "from matplotlib.patches import Polygon"
      ],
      "metadata": {
        "id": "-wknqObHF-LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"Apply the given mask to the image.\n",
        "    \"\"\"\n",
        "    for c in range(3):\n",
        "        image[:, :, c] = np.where(mask == 1,\n",
        "                                  image[:, :, c] *\n",
        "                                  (1 - alpha) + alpha * color[c] * 255,\n",
        "                                  image[:, :, c])\n",
        "    return image"
      ],
      "metadata": {
        "id": "ktfG5NSGGHbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6NoiN-kNNpf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "for path in list_path_file:\n",
        "  image = cv2.imread(path)\n",
        "  try:\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    r = model_final.detect([image])[0]\n",
        "    img = display_instances_custom(image, r['rois'], r['masks'], r['class_ids'], class_names = 'SS')\n",
        "  except:\n",
        "    print(path.split('/')[-1])\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(img)"
      ],
      "metadata": {
        "id": "oud9RGVpNM0n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}